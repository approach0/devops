[a0-web-pack]
exe = $SSH 'npm install uglify-js -g && cd a0/demo/web/ && ./pack.sh'
dep[] = repo:a0-build
dep[] = base-software:node-env-install

[a0-publish]
exe = $SSH 'rsync -ru --delete --progress a0/demo/web/. /var/www/html/search'
dep[] = deploy:a0-web-pack
dep[] = httpd:http-update

[a0-demo-link]
exe = $SSH 'ln -sf /var/www/html/search /var/www/html/demo'
dep[] = deploy:a0-publish

[a0-index-feed]
exe = echo $INDEX_FEEDER_RUN && $INDEX_FEEDER_RUN

[a0-index-upload]
exe = rsync -z --partial --progress $INDEX_IMG $RSYNC_ADDR/$(basename $INDEX_IMG)
dep[] = rsyncd:list

[a0-ready-run]
# this script will also kill existing a0 search daemons
exe = $SSH 'bash -s' -- < $SCRIPT/a0-update-index-img.sh "$(basename $INDEX_IMG)" $RANK
dep[] = deploy:a0-demo-link
dep[] = deploy:a0-index-upload
dep[] = base-software:start-tmux-server

[a0-killed]
exe = $SSH "tmux kill-session -t 'searchd' || true"

[a0-inspect]
exe = $SSH "tmux capture-pane -pt 'searchd'"

[a0-master]
exe = $SSH "tmux new -d -s 'searchd' '$A0_MASTER_RUN' && echo $A0_MASTER_RUN && sleep 2 && tmux capture-pane -pt 'searchd'"
if = [ $RANK -eq 0 ]
dep[] = deploy:a0-ready-run
dep[] = deploy:a0-killed

[a0-crawler-make-dir]
exe = $SSH "mkdir -p ~/corpus && mkdir -p ~/crawl-$RANK"

[a0-crawler-setup-dir]
exe = $SSH "cd ~/crawl-$RANK && cp ../a0/demo/crawler/*.py . && cp ../a0/demo/crawler/*.html . && ln -sf ~/corpus ./tmp"
dep[] = repo:a0-code
dep[] = deploy:a0-crawler-make-dir

[a0-crawler-modules]
exe = $SSH 'pip3 install BeautifulSoup4 pycurl slimit'
dep[] = repo:base

[a0-crawler-kill]
exe = $SSH "tmux kill-session -t 'crawler-$RANK' || true"
dep[] = repo:base

[a0-crawler-run]
exe = $SSH "tmux new -d -s 'crawler-$RANK' 'cd ~/crawl-$RANK && ./$CRAWLER_RUN'"
dep[] = deploy:a0-crawler-setup-dir
dep[] = deploy:a0-crawler-kill
dep[] = deploy:a0-crawler-modules

[a0-corpus-harvest]
# run script every Monday at 2:03 am
timer = 0 3 2 * * 1
exe = rsync -zauv --progress $RSYNC_ADDR/corpus/ $HARVEST_DIR
dep[] = deploy:a0-crawler-make-dir

[a0-crawler-inspect]
exe = $SSH "tmux capture-pane -pt 'crawler-$RANK'"
dep[] = repo:base

[a0-crawler-cnt-files]
exe = $SSH "find ~/corpus -name '*.json' | wc -l"
dep[] = repo:base
